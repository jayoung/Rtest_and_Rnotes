
# interpreting strings as variable names
x <- 42
eval(parse(text = "x"))

# remove all variables whose names match the pattern "temp":
rm(list=ls(pat="temp"))


R preferences/profiles/startup/environmental variables
-----------------------------------------
.libPaths()
~/.Rprofile
./.Rproj.user
./*Rproj
./.Rhistory
.Renviron

You can run R without any startup files by using the --vanilla argument when starting R

https://rstats.wtf/r-startup.html


installing additional packages in Unix R
-----------------------------------------
chooseCRANmirror()
  and select a local one, e.g. 65: USA (WA)
install.packages("ape", dependencies = TRUE)
(in Mac R, just use the package manager and installer menu options)

in rare cases, a package is available from elsewhere, not the usual place:
install.packages("Vennerable", repos="http://R-Forge.R-project.org") 
## needed to do this on Mac
install.packages("Vennerable", repos="http://R-Forge.R-project.org", type="source")

## another rare case of a package coming from elsewhere:
install.packages("devtools")
library(devtools)
install_github("easyGgplot2", "kassambara")
install_github("js229/Vennerable")


or:
update.packages(ask=FALSE)

and to use the package:
library("gtools")

 .libPaths(/home/btrask/traskdata/lib_linux/R)
(to add private library path in linux)

.Rprofile gets read when I start up R, so I can put functions I use regularly in there.

Now I have aliases 
R = R for Bioconductor-release packages
RbiocDevel = R for Bioconductor-devel packages

for bioconductor packages:
## old way:
use this: 
    myBiocLite()
    myBiocLite(c("Rsamtools","BSgenome.Scerevisiae.UCSC.sacCer2"), test=TRUE)
    myBiocLite(c("Rsamtools","BSgenome.Scerevisiae.UCSC.sacCer2"))
rather than the regular biocLite()

source('http://bioconductor.org/biocLite.R')
biocLite()
   or
biocLite(lib.loc=.libPaths()[1])

## new way:
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("Biostrings", lib="/home/jayoung/malik_lab_shared/linux_gizmo/R_packages")

to remove a package: 
remove.packages("checkmate", "/fh/fast/malik_h/grp/malik_lab_shared/linux_gizmo/R_devel_packages")

using the lib.loc thing suppresses the unnecessary updating of any packages that are out of date in /app/R/3.2.1/lib/R/library but current in /fh/fast/malik_h/grp/malik_lab_shared/linux_gizmo/R_packages


biocLite(c('annotate', 'hgu95av2'), lib.loc=.libPaths()[1])


old: or to update all bioc packages:
source("http://www.bioconductor.org/biocLite.R")
biocLite("Biobase")
library(Biobase)
repos <- biocReposList()
update.packages(repos=repos, ask=FALSE)

update.packages(repos=repos, ask=FALSE,lib.loc="/home/jayoung/R/x86_64-unknown-linux-gnu-library/2.13",instlib="/home/jayoung/R/x86_64-unknown-linux-gnu-library/2.13")

library(ShortRead,lib.loc="/home/jayoung/R/")
library(ShortRead,lib.loc="/home/jayoung/R/x86_64-unknown-linux-gnu-library/2.13")


### on Mac - sometimes the binary is busted but the source will work - can specify source like this:
biocLite("Biobase",type="source")

biocLite("ShortRead",type="source")  ### does get the dependencies, too

to see changes/updates to Bioc packages:
svn log -v https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/ShortRead | less
(username and password both readonly. does not work on all nodes. try devhost queue, 64-bit nodes, lamprey)


(on bedrock, it may help to do this first:
setenv PATH /opt/gcc/bin:/usr/bin:/sbin:/usr/sbin:/usr/sfw/bin:/opt/sfw/bin:/usr/xpg4/bin:/usr/ccs/bin:/usr/local/bin:/opt/torque/bin:/home/mrg/bin
setenv LD_LIBRARY_PATH /home/mrg/apps/sparc-sun-solaris-2.10/lib:/usr/sfw/lib:/opt/sfw/lib

then to start up R, need to do this: ~/traskdata/bin/R

)

to download and install the devel version of a package: 
svn co https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/GenomicRanges
tar -cf - GenomicRanges | gzip -c - > GenomicRanges.tar.gz
Rdevel CMD INSTALL GenomicRanges.tar.gz

or, to install a package from a tar.gz file from the unix command line:
R CMD INSTALL GEOquery_2.1.8.tar.gz

to find out a package version, including details on where it was loaded from:
installed.packages()["R.utils","Version"]
installed.packages()["seqLogo",]

to use a function that's not exported from a package (it's hidden), use three : symbols,  e.g. seqLogo:::addLetter()

remove.packages("subplex")



BEWARE: partial row name matching when using [ to subset.

I might want to use R's GUI script editor when working on Mac?

getting help
-------------
see
http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Graves~et~al.pdf

help(plot)
help.search("plot")

help(package="BiocInstaller")
will list the functions

library(sos) 
PL <- findFn("Petal.Length")  
#### seems like it goes through lots of R docs, finds help pages for any function that mentions Petal.Length. When I then call PL, it shoots up an html page with links to all of those

RSiteSearch("Petal.Length")  
### shoots up a web page with links to lots of things mentioning Petal.Length. From utils package. 

library(Biobase)
openVignette(package="seqLogo") #### openVignette is a Biobase function

vignette()  
   lists all vignettes
vignette(package="grid")
   lists grid's vignettes
vignette("saveload")  
   to load a specific vignette (this one is from the grid package)
vignette("rotated", package="grid")
   might need to do this to load vignettes from specific packages??

or: 
openVignette("ShortRead")


library(help = grid)
   lists functions in a package and vignettes
   
v1 <- vignette("grid")
print(v1)  ### brings up the pdf
edit (v1)  ### brings up the associated R code

v1 <- vignette("KEGGgraph")
print(v1)  ### brings up the pdf
edit (v1)  ### brings up the associated R code


workflows:
http://cran.r-project.org/web/views/
http://www.bioconductor.org/help/workflows/


glob2rx("file*.txt")   ### a useful way to convert regular expression I'd use on command line to an R expression

installing Rmpi:

wants sprng.h and mpi.h (sprng is for the dependency package rsprng)

setenv LD_LIBRARY_PATH ${LD_LIBRARY_PATH}:/usr/lib64
install.packages("Rmpi", dependencies=TRUE)

install.packages("Rmpi", dependencies=TRUE, configure.args="--with-mpi=/usr/lib64/mvapich2/1.4-gcc/include") 

setenv LD_LIBRARY_PATH ${LD_LIBRARY_PATH}:/usr/lib64:/usr/lib64/mvapich2/1.4-gcc/lib
install.packages("Rmpi", configure.args="--with-mpi=/usr/lib64/mvapich2/1.4-gcc") 





### to investigate environmental variables:
Sys.getenv("LD_LIBRARY_PATH")
temp <- Sys.getenv()
names(temp)
temp[grep ("btrask",temp)]
temp[grep ("lib_linux",temp)]

Note - they are different within R. The file /home/jayoung/traskdata/lib_linux_64_hyrax/R/etc/ldpaths
gets read to modify paths within R.

see also /home/jayoung/traskdata/lib_linux_64_hyrax/R/etc/Renviron
Useful packages
---------------

Phylogenies:  
ape
ggtree (can parse PAML and Hyphy output as well as make some very nice plots)
https://yulab-smu.top/treedata-book
https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12628

Plotting genes:
gggenes:  https://cran.r-project.org/web/packages/gggenes/vignettes/introduction-to-gggenes.html

Useful web pages
---------------
http://manuals.bioinformatics.ucr.edu/home/ht-seq

https://rfortherestofus.com/resources/ to find packages and tutorials

some example R commands:
------------------------

read data in from a tab-delimited table
data<-read.delim("file.txt")
(if the first row has one fewer values than the rest of the rows, R will assume that the first column contains row names)
data<-read.delim("file.txt",header=FALSE)
perhaps want to use as.is=TRUE to prevent the nutty factor making behavior.


listresultingfromstrsplit <- strsplit(rawlanes[,"samplenorep"],"_")
allfirstelementsoflist <- sapply (listresultingfromstrsplit , "[" , 1)
allsecondelementsoflist <- sapply (listresultingfromstrsplit , "[" , 2)

eapply applies across all elements of an environment

save.image(file="expn.RData")

list.files() 
getwd()
setwd("Rdata")
setwd("..")
history(max.show=100)
write.table(arrayname,file="outfile.txt",sep="\t",row.names=FALSE,col.names=FALSE)

t(arrayname)
transposes the array (swaps rows and columns)

class()
str(myobject)  #### shows all kinds of internals of the object

ordering factors:
list<-c("1to1low","1to1medium","1to1high")
data$Category = factor( data$Category, levels = list)
data$Category held a bunch of values selected from 1to1low, 1to1medium and 1to1high. the factor command orders the levels of the factor so that any subsequence anaylses the categories get counted in a particular order (e.g. boxplot, table)


library(Biostrings)
detach(package:Biostrings) ### the opposite

detach(package:multicore,unload=TRUE)


is.infinite

with - takes e.g. a dataframe and constructs an environment from it so you can e.g. just use column names as variables rather than specifying dataframe[,colname]


str:  quick view on any object
dir.create
download.file

na.omit  (omits rows where values in any column are NA)
drop_na  (tidyverse version of na.omit)


to run from the unix command line:
---------------------------------
R CMD BATCH < Rcontrolfile.R

seems to work better like this:
R CMD BATCH Rcontrolfile.R

(output automatically goes to Rcontrolfile.Rout)

general plotting
----------------
quartz(width=7.5,height=10)
X11(width=7.5,height=10)
sets size of plotting window (quartz for Mac, X11 for bedrock)
dev.print(postscript,file="temp.ps",horizontal=FALSE)
copies contents of the plot window to a postscript file. useful on bedrock.

a unix command to convert pdf to png (e.g. for plots with many points that take forever to print)

convert -density 600x600 a.pdf a.png 

par(cex=0.7)
makes the whole plot smaller
par(cex.axis=0.7)

par(mfrow=c(2,1))
sets up plotting window to expect two plots one above the other

par(mfrow=c(4,3),oma=c(0, 0, 2, 0),mar = c(5.1, 4.1, 2.1, 2.1))
mtext("Zhang array data, V1Rs",side=3,outer=TRUE,line=0)
adds main title to multi-plot device, and makes individual margins smaller

dev.print(postscript,file="temp.ps",horizontal=FALSE)

variable naming 
---------------
x<-1:10
stringx <- "x"
get(stringx)

get lets you use a string to store variable names


boxplots:
--------
boxplot(omega~nonconscode,data=data98yesno,xlab="number of non-consensus residues per pair", ylab = "omega", main="noncons98, LeoMR05nonpseud, omega")
omega and nonconscode are column titles in the data matrix - this will plot the omegas classified by the tag in nonconscode
xlab is x axis label, main is title

let's say I want to make a boxplot of a dataframe (called df), where each boxplot item is a column of the data.frame:

boxplot(list(x=x,y=y))

boxplot(df, (rep(colnames(df),each=dim(df)[1])) )


violin plots
------------

I found three different packages that can make violin plots. I like PlotViolin better than vioplot, but when I run it on large datasets it is very slow if I allow it to use its default bandwidth selection algorithm.   If I specify the bw="nrd0" option, it is MUCH quicker.

library(vioplot)       # function = vioplot
library(DescTools)     # function = PlotViolin
library(easyGgplot2)   # function = ggplot2.violinplot
library(UsingR)        # function = violinplot


# http://www.sthda.com/english/wiki/ggplot2-violin-plot-easy-function-for-data-visualization-using-ggplot2-and-r-software

## test data: a bimodal distribution (x1 or x2), with means at 0 (2/3 of the datapoints) and 5 (1/3 of the datapoints).  Also, make a factor (f1 or f2) that divides the data into 5 groups. 

mySmallNumber <- 100  ### my dataset will be 1.5 times this big:
x1 <- c(rnorm(mySmallNumber), rnorm(mySmallNumber/2,5))
f1 <- factor(rep(1:5, (1.5*mySmallNumber)/5))
df1 <- data.frame(x1=x1, f1=f1)

myBigNumber <- 100000  ### my dataset will be 1.5 times this big:
x2 <- c(rnorm(myBigNumber), rnorm(myBigNumber/2,5))
f2 <- factor(rep(1:5, (1.5*myBigNumber)/5))
df2 <- data.frame(x2=x2, f2=f2)


####### simply plot all the data as one group:
system.time(PlotViolin(x2))
   ## 90 seconds!!
system.time(vioplot(x2))
    ## < 1 second but I don't like the way it chooses bandwidth - too coarse-grained
system.time(PlotViolin(x2, bw="nrd0"))
   ## much quicker!  and, I like the bandwidth choice. 

ggplot2.violinplot(data=x2)

ggplot2.violinplot(data=x2, addMean=TRUE, meanPointShape=23, meanPointSize=3, meanPointColor="black", meanPointFill="blue" )

violinplot(x2,col="brown")


###### subsetting the data: I have not figured out with any of these functions how to zoom in on a portion of the distrubution - I can subset the data that goes into the distribution plot, but I cannot figure out how to just truncate the portion that is displayed.

ggplot2.violinplot(data=x2, ylim=c(0,5))
# Warning message:
# Removed 75079 rows containing non-finite values (stat_ydensity). 

violinplot(x2~f2,col="brown", ylim=c(0,5) )

#### don't know how to do it with PlotViolin - neither of these works:
#  PlotViolin(x2, bw="nrd0", subset=x2<5 ) 
#  PlotViolin(x2 ~ f2, bw="nrd0", xlab="x axis", ylab="y axis", ylim=c(0,5) ) 

####### plot the data by groups: 
system.time(PlotViolin(x2 ~ f2, bw="nrd0"))

ggplot2.violinplot(data=df2, xName="f2",yName="x2",addMean=TRUE)

violinplot(x2~f2,col="brown")

## for vioplot, need a special hacked version of the function in order to pass in a list as input: got this from http://stackoverflow.com/questions/22410606/violin-plot-with-list-input:

vioplot2( split(x2, f2) )

vioplot2<-function (x, ..., range = 1.5, h = NULL, ylim = NULL, names = NULL, 
    horizontal = FALSE, col = "magenta", border = "black", lty = 1, 
    lwd = 1, rectCol = "black", colMed = "white", pchMed = 19, 
    at, add = FALSE, wex = 1, drawRect = TRUE) 
{
    if(!is.list(x)){
        datas <- list(x, ...)
    } else{
        datas<-x
    }
    n <- length(datas)
    if (missing(at)) 
        at <- 1:n
    upper <- vector(mode = "numeric", length = n)
    lower <- vector(mode = "numeric", length = n)
    q1 <- vector(mode = "numeric", length = n)
    q3 <- vector(mode = "numeric", length = n)
    med <- vector(mode = "numeric", length = n)
    base <- vector(mode = "list", length = n)
    height <- vector(mode = "list", length = n)
    baserange <- c(Inf, -Inf)
    args <- list(display = "none")
    if (!(is.null(h))) 
        args <- c(args, h = h)
    for (i in 1:n) {
        data <- datas[[i]]
        data.min <- min(data)
        data.max <- max(data)
        q1[i] <- quantile(data, 0.25)
        q3[i] <- quantile(data, 0.75)
        med[i] <- median(data)
        iqd <- q3[i] - q1[i]
        upper[i] <- min(q3[i] + range * iqd, data.max)
        lower[i] <- max(q1[i] - range * iqd, data.min)
        est.xlim <- c(min(lower[i], data.min), max(upper[i], 
            data.max))
        smout <- do.call("sm.density", c(list(data, xlim = est.xlim), 
            args))
        hscale <- 0.4/max(smout$estimate) * wex
        base[[i]] <- smout$eval.points
        height[[i]] <- smout$estimate * hscale
        t <- range(base[[i]])
        baserange[1] <- min(baserange[1], t[1])
        baserange[2] <- max(baserange[2], t[2])
    }
    if (!add) {
        xlim <- if (n == 1) 
            at + c(-0.5, 0.5)
        else range(at) + min(diff(at))/2 * c(-1, 1)
        if (is.null(ylim)) {
            ylim <- baserange
        }
    }
    if (is.null(names)) {
        label <- 1:n
    }
    else {
        label <- names
    }
    boxwidth <- 0.05 * wex
    if (!add) 
        plot.new()
    if (!horizontal) {
        if (!add) {
            plot.window(xlim = xlim, ylim = ylim)
            axis(2)
            axis(1, at = at, label = label)
        }
        box()
        for (i in 1:n) {
            polygon(c(at[i] - height[[i]], rev(at[i] + height[[i]])), 
                c(base[[i]], rev(base[[i]])), col = col, border = border, 
                lty = lty, lwd = lwd)
            if (drawRect) {
                lines(at[c(i, i)], c(lower[i], upper[i]), lwd = lwd, 
                  lty = lty)
                rect(at[i] - boxwidth/2, q1[i], at[i] + boxwidth/2, 
                  q3[i], col = rectCol)
                points(at[i], med[i], pch = pchMed, col = colMed)
            }
        }
    }
    else {
        if (!add) {
            plot.window(xlim = ylim, ylim = xlim)
            axis(1)
            axis(2, at = at, label = label)
        }
        box()
        for (i in 1:n) {
            polygon(c(base[[i]], rev(base[[i]])), c(at[i] - height[[i]], 
                rev(at[i] + height[[i]])), col = col, border = border, 
                lty = lty, lwd = lwd)
            if (drawRect) {
                lines(c(lower[i], upper[i]), at[c(i, i)], lwd = lwd, 
                  lty = lty)
                rect(q1[i], at[i] - boxwidth/2, q3[i], at[i] + 
                  boxwidth/2, col = rectCol)
                points(med[i], at[i], pch = pchMed, col = colMed)
            }
        }
    }
    invisible(list(upper = upper, lower = lower, median = med, 
        q1 = q1, q3 = q3))
}




XY scatterplots:
-----------------
plot(alldS,alldN,type="n",xlim=c(0,0.5),ylim=c(0,0.2),xlab="dS",ylab="dN",main="dN dS, all non-pseud pairs, by Zhang MOE expression status")
points(MOEenriched[,"dS"],MOEenriched[,"dN"],pch=20,cex=.5,col="red")
points(MOEenriched_marginal[,"dS"],MOEenriched_marginal[,"dN"],pch=20,cex=.5,col="green")
points(MOEnotenriched[,"dS"],MOEnotenriched[,"dN"],pch=20,cex=.5,col="black")

leg.txt<-c("MOEenriched","MOEenrichedmarginal","MOEnotenriched")
legend("topright",leg.txt,pch=20,col=c("red","green","black"))

histograms
----------
hist(recS,xlab="RecombSHRSPxBN",br=20,main="Recombination rate all intervals")
recS is an array
br=20 gives 20 categories
main is title
xlab is x label

to plot two histograms side by side, the data must be in list form, and use multhist from plotrix package:
require(plotrix)
mylist<-list(OR=OR[,2],V1R=V1R[,2])
cols<-grey.colors(2)
multhist(mylist,col=cols,main="Genomic clusters, using 0.5Mb cutoff, num genes")
leg.txt<-c("OR","V1R")
legend("topright",leg.txt,col=cols,fill=cols)


density plot
-------------
library(KernSmooth)
x<-cbind(ORs$Testis_1,ORs$OE_M0)
est<-bkde2D(x,bandwidth=c(10,10))
contour(est$x1,est$x2,est$fhat,xlim=c(-500,500),ylim=c(-500,500))

(makes contour plot of density function of points in the two columns of ORs data table labelled Testis_1 and OE_M0. change the bandwidth to alter smoothing)

or, using smoothScatter:
pairs(exprs[,allsamples], panel=function(...) {par(new=TRUE);smoothScatter(...,nrpoints=0)})

or, without smoothing (but this is inefficient with large data)
Lab.palette <- colorRampPalette(c("blue", "orange", "red"), space = "Lab")
dcols <- densCols(x,y,colramp = Lab.palette)
graphics::plot(x, y, col = dcols, pch=20, main = "n = 1000")

?venn - can do >3 way venn diags.

mosaic plots for categorical data
---------------------------------
plot(familycounts,xlab="Family",ylab="OrthoFuller",main="OrthoFuller by Family",color=rainbow(8),las=1)
(familycounts is a table of counts, las=1 just specifies category labels always horizontal, color allows you to specify the palette used - this case there were 8 categories, so palette includes 8 colors)

pairs plots
----------

upPan<- function (...) {
    points(...,col="darkblue")
    abline(a=0,b=1,col="red")
}
lowPan<-function(x,y,...) {
    text(mean(par("usr")[1:2]), mean(par("usr")[3:4]), signif(cor(x,y,use="complete.obs"),2),cex=2)
}
pairs(meths2[,braincols],pch=".", upper.panel=upPan, lower.panel=lowPan)

(meths2[,braincols] specifies a data frame with a whole bunch of columns of numbers where we want to compare all columns versus each other)
(signif rounds to 2 significant figures)
(mean(par("usr")[1:2]), mean(par("usr"))[3:4] determines co-ordinates for the midpoint of the plot)


statistical tests
------------------
t.test(omegas98yesno~nonconscode98yesno,data98yesno)
does a t-test on the omegas98yesno array, classifying the values by the corresponding two categories in nonconscode98yesno (note that t-tests are only appropriate for samples drawn from a normal distribution)


wilcox.test(omega ~ nonconscode,data=data98yesno)
performs wilcoxon rank sum test (like t-test but for non-normal data) on omegas in data98yesno, as grouped into two classes by the nonconscode column which has exactly two classes

wilcox.test(omega ~ nonconscode,data=data98,subset = nonconscode %in% c("Azero","Bone"))
if there are more than two classes, we can pick out the two of interest like this.

wilcox.test(recORno,recORyes)
wilcoxon rank sum test on two arrays rexORno and recORyes



subsets of the data
-------------------
tapply(omegas98yesno,nonconscode98yesno,summary)
omegasyesno is one array
nonconscode98yesno is a second array, same length, that classifies the elements in the first array
summary is the function that will be performed on each class of values in the first array

subset(airquality, Temp>80, select = c(Ozone, Temp))
takes subset of the table airquality where the value in the Temp column is > 80 and only takes the Ozone and Temp columns

subset(airquality, Day == 1, select = -Temp)
takes all columns except Temp

with(airquality, subset(Ozone, Temp > 80))
takes the subset of the table where Temp > 80, just Ozone column, and returns results as simple vector (not as column of a new table)

dim(ratrec)
gives dimensions of a data matrix
length(list)
gives length of a list


tables
------
attach(nonconsbyseq)
JYtable<-table(ortholog_type,noncons98)
addmargins(JYtable)
sqsm <- function( x ) sum( x )^2/100
round(sweep(addmargins(JYtable, 1, list(list(All=sum, N=sqsm))), 2, apply( JYtable, 2, sum )/100, "/"),1)
     (by column)     
     
round(sweep(addmargins(JYtable, 2, list(list(All=sum, N=sqsm))), 1, apply( JYtable, 1, sum )/100, "/"),1)
     (by row)
  try to understand this command:
    FIRST = addmargins(JYtable, 2, list(list(All=sum, N=sqsm))) - this part adds sum and sqsm to each column
    SECOND = apply( JYtable, 1, sum ) - this part specifies a table of row sums
    THIRD = sweep(FIRST, 1, SECOND/100, "/"):
         FIRST gives the matrix of values to work on
         1 somehow specifies we're working on rows (2 for columns)
         SECOND gives the table of row sums
         "/" ensures each cell is divided by the relevant entry in the row sums table
    round (THIRD, 1)  - rounds everything to 1 decimal place
    
    
chisq.test(JYtable)
chisq.test(JYtable)$obs
chisq.test(JYtable)$exp



simulations
-----------
rbinom(100,1,0.35)
samples 100 values from a binomial distribution of 1s and 0s, where 0.35 of the distribution are 1s.

rnorm


loops
-----
for (i in 2:10) wss[i] <- sum(kmeans(planet.dat,centers = i)$withinss)
		(can use {} for longer loops)

conditionals
------------
   if (sum(col)==0) { 
      ngroups<-c(ngroups,"NA")
      models<-c(models,"NA")
      next
   }


matching
--------
genesymbols<-mget(featureNames(exSet),hgu95av2SYMBOL)
thisprobe<-which(genesymbols=="SLC6A2")


tree coloring and heatmaps:
---------------------------

ape package. see ~/Rscripts/colortree.R
can also explore layout, zoom functions

other tree notes:
This might be useful for tree coloring:
source("http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/My_R_Scripts/dendroCol.R") # Import tree coloring function..
dend_colored <- dendrapply(as.dendrogram(hr), dendroCol, keys=subcl, xPar="edgePar", bgr="red", fgr="blue", pch=20) # In this example the dendrogram for the above 'hr' object is colored with the imported 'dendroCol()' function based on the identifiers provided in its 'keys' argument. If 'xPar' is set to 'nodePar' then the labels are colored instead of the leaves.

contents of this webpage:
http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/My_R_Scripts/dendroCol.R###################################
## Function to Color Dendrograms ##
###################################
dendroCol <- function(dend=dend, keys=keys, xPar="edgePar", bgr="red", fgr="blue", pch=20) {
        if(is.leaf(dend)) {
                myattr <- attributes(dend)
                if(length(which(keys==myattr$label))==1){
                attr(dend, xPar) <- c(attr$edgePar, list(lab.col=fgr, col=fgr, pch=pch))
                } else {
                attr(dend, xPar) <- c(myattr$edgePar, list(lab.col=bgr, col=bgr, pch=pch))
                }
        }
  return(dend)
}
# Usage: 
# dend_colored <- dendrapply(dend, dendroCol, keys, xPar="edgePar", bgr="red", fgr="blue", pch=20) # use xPar="nodePar" to color tree labels
# plot(dend_colored, horiz=T)

# Color function to generate green-red heat maps
heatmap(y, Rowv=as.dendrogram(hr), Colv=as.dendrogram(hc), col=my.colorFct(), scale="row") 
my.colorFct <- function(n = 50, low.col = 0.45, high.col=1, saturation = 1) { 
	if (n < 2) stop("n must be greater than 2")
	n1 <- n%/%2
	n2 <- n - n1
	c(hsv(low.col, saturation, seq(1,0,length=n1)), hsv(high.col, saturation, seq(0,1,length=n2))) 
}


some commands to look at memory usage (don't know how to use these yet)
--------------

gc - looks useful
object.size
mem.limits
?Memory
Rprof
summaryRprof

(Rmpi package for parallelizing?)

Rprofmem and tracemem (must be enabled at compile time)

memory.profile - doesn't look useful


use secondary y-axis:
---------------------

http://www.r-bloggers.com/r-graph-with-two-y-axes/

x <- 1:5
y1 <- rnorm(5)
y2 <- rnorm(5,20)

plot(x,y1,type="l",col="red")
par(new=TRUE)
plot(x, y2,type="l",col="blue",xaxt="n",yaxt="n",xlab="",ylab="")
axis(4)
mtext("y2",side=4,line=3)
legend("topleft",col=c("red","blue"),lty=1,legend=c("y1","y2"))



to use Arial font, in R: (modified from PLoS Genet instructions)
---------------------
http://www.plosgenetics.org/static/figureGuidelines.action#arialR

postscript(file="try.ps", horizontal=F,onefile=F,width=4, height=4,
   family=c("/home/jayoung/fontFiles/arial.afm",
            "/home/jayoung/fontFiles/arialbd.afm",
            "/home/jayoung/fontFiles/ariali.afm",
            "/home/jayoung/fontFiles/arialbi.afm"),  pointsize=12)
hist(rnorm(100))
dev.off()

For PLoS submissions, it seems I have to save from R as a postscript, to make sure fonts aren't screwed up (when I save as pdf, some points in graphs use an unidentified font, which Illustrator converts to AdobePiStd, which PLoS website doesn't recongize). Then I use AI to save as eps (make sure I choose encapsulated fonts)

More advice here:
http://r.789695.n4.nabble.com/pdf-device-uses-fonts-to-represent-points-data-alteration-td836140.html

To make the figures look the right size, I also changed three lines in the eps file using a text editor (if I don't do that, they re-scale to fill the whole page): 
%%BoundingBox: 0 0 612 792
%%HiResBoundingBox: 0 0 612 792
%%CropBox: 0 0 612 792




############ showing colors 

totalColors <- length(colors())
# 657 of them

plotCols <- function(firstColorIndex, lastColorIndex) {
    plot(0, 0, type = "n", xlim = c(0, 1), ylim = c(0, 1),  
         axes = FALSE, xlab = "", ylab = "")
    
    numRows <- 42
    numColumns <- 8
    textXoffset <- 0.1 * 1/numColumns
    textYoffset <- 0.375 * 1/numRows
    myColors <- colors()[seq(firstColorIndex,lastColorIndex)]
    
    rect( rep((0:(numColumns - 1)/numColumns),numRows) ,
          sort(rep((0:(numRows - 1)/numRows),numColumns),decreasing=T),
          rep((1:numColumns/numColumns),numRows) , 
          sort(rep((1:numRows/numRows),numColumns),decreasing=T), 
              border = "light gray", 
              col=myColors)
    
    text( rep((0:(numColumns - 1)/numColumns),numRows) + textXoffset , 
          sort(rep((0:(numRows - 1)/numRows),numColumns),decreasing=T) + textYoffset ,  
          myColors, adj=0,
        cex=0.5)

}




pdf(file="RcolorDemo.pdf", width=7,height=11)
par(mar=c(0,0,0,0))
plotCols(1, 336)
plotCols(337, totalColors)
dev.off()



######
parsing fastq output:

see ngsReports package - ~/public_databases/NCBI/SRA/data/mammalian_expression_profiles/human/human_spermMicrobiomeTotalRNAseq/fastqc/parseFastqc.R

https://www.bioconductor.org/packages/devel/bioc/vignettes/ngsReports/inst/doc/ngsReportsIntroduction.html#loading-fastqc-data-into-r

###### reading files from a .zip file:


## the first argument is the zip file, the second is the path that would result once the zip is unpacked
con <- unz("SRR10696710_fastqc.zip", "SRR10696710_fastqc/fastqc_data.txt")
dat <- scan(con, what="character")


#### wordclouds - wordcloud and wordcloud2 packages
see /Volumes/malik_h/user/jayoung/presentations/MalikLab/otherSlides_mine/KennedyHighSchoolVisit_2021_Dec7/Hutch_wordCloud.R


##### Rstudio 

sometimes have trouble with it acting super slow and weird. Seems to be with things stored on network drive, particularly when using Rprojects in dirs I'm syncing to github.

Advice:
https://community.rstudio.com/t/rstudio-startup-time-40-seconds/26174/8?u=kevinushey
disable a bunch of stuff in Rstudio preferences:
- disable git/svn version control
- disable everything under code-diagnostics


####### bug reports using reprex: 
https://www.tidyverse.org/help/#reprex
